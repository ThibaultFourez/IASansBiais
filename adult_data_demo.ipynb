{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "from prepare_adult_data import *\n",
    "sys.path.insert(0, '../../fair_classification/') # the code for fair classification is in this directory\n",
    "import utils as ut\n",
    "import loss_funcs as lf # loss funcs that can be optimized subject to various constraints\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adult_data(load_data_size=None): #Ne marche pas quand on l'importe alors qu'elle est identique...\n",
    "\n",
    "    \"\"\"\n",
    "        if load_data_size is set to None (or if no argument is provided), then we load and return the whole data\n",
    "        if it is a number, say 10000, then we will return randomly selected 10K examples\n",
    "    \"\"\"\n",
    "    attrs = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country'] # all attributes\n",
    "    int_attrs = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week'] # attributes with integer values -- the rest are categorical\n",
    "    sensitive_attrs = ['sex', 'race'] # the fairness constraints will be used for this feature\n",
    "    attrs_to_ignore = ['sex', 'race' ,'fnlwgt'] # sex and race are sensitive feature so we will not use them in classification, we will not consider fnlwght for classification since its computed externally and it highly predictive for the class (for details, see documentation of the adult data)\n",
    "    attrs_for_classification = set(attrs) - set(attrs_to_ignore)\n",
    "\n",
    "    # adult data comes in two different files, one for training and one for testing, however, we will combine data from both the files\n",
    "    data_files = [\"adult.data\", \"adult.test\"]\n",
    "\n",
    "\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    x_control = {}\n",
    "\n",
    "    attrs_to_vals = {} # will store the values for each attribute for all users\n",
    "    for k in attrs:\n",
    "        if k in sensitive_attrs:\n",
    "            x_control[k] = []\n",
    "        elif k in attrs_to_ignore:\n",
    "            pass\n",
    "        else:\n",
    "            attrs_to_vals[k] = []\n",
    "\n",
    "    for f in data_files:\n",
    "        check_data_file(f)\n",
    "\n",
    "        for line in open(f):\n",
    "            line = line.strip()\n",
    "            if line == \"\": continue # skip empty lines\n",
    "            line = line.split(\", \")\n",
    "            if len(line) != 15 or \"?\" in line: # if a line has missing attributes, ignore it\n",
    "                continue\n",
    "\n",
    "            class_label = line[-1]\n",
    "            if class_label in [\"<=50K.\", \"<=50K\"]:\n",
    "                class_label = -1\n",
    "            elif class_label in [\">50K.\", \">50K\"]:\n",
    "                class_label = +1\n",
    "            else:\n",
    "                raise Exception(\"Invalid class label value\")\n",
    "\n",
    "            y.append(class_label)\n",
    "\n",
    "\n",
    "            for i in range(0,len(line)-1):\n",
    "                attr_name = attrs[i]\n",
    "                attr_val = line[i]\n",
    "                # reducing dimensionality of some very sparse features\n",
    "                if attr_name == \"native_country\":\n",
    "                    if attr_val!=\"United-States\":\n",
    "                        attr_val = \"Non-United-Stated\"\n",
    "                elif attr_name == \"education\":\n",
    "                    if attr_val in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "                        attr_val = \"prim-middle-school\"\n",
    "                    elif attr_val in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "                        attr_val = \"high-school\"\n",
    "\n",
    "                if attr_name in sensitive_attrs:\n",
    "                    x_control[attr_name].append(attr_val)\n",
    "                elif attr_name in attrs_to_ignore:\n",
    "                    pass\n",
    "                else:\n",
    "                    attrs_to_vals[attr_name].append(attr_val)\n",
    "\n",
    "    def convert_attrs_to_ints(d): # discretize the string attributes\n",
    "        for attr_name, attr_vals in d.items():\n",
    "            if attr_name in int_attrs: continue\n",
    "            uniq_vals = sorted(list(set(attr_vals))) # get unique values\n",
    "\n",
    "            # compute integer codes for the unique values\n",
    "            val_dict = {}\n",
    "            for i in range(0,len(uniq_vals)):\n",
    "                val_dict[uniq_vals[i]] = i\n",
    "\n",
    "            # replace the values with their integer encoding\n",
    "            for i in range(0,len(attr_vals)):\n",
    "                attr_vals[i] = val_dict[attr_vals[i]]\n",
    "            d[attr_name] = attr_vals\n",
    "\n",
    "    \n",
    "    # convert the discrete values to their integer representations\n",
    "    convert_attrs_to_ints(x_control)\n",
    "    convert_attrs_to_ints(attrs_to_vals)\n",
    "\n",
    "\n",
    "    # if the integer vals are not binary, we need to get one-hot encoding for them\n",
    "    for attr_name in attrs_for_classification:\n",
    "        attr_vals = attrs_to_vals[attr_name]\n",
    "        if attr_name in int_attrs or attr_name == \"native_country\": # the way we encoded native country, its binary now so no need to apply one hot encoding on it\n",
    "            X.append(attr_vals)\n",
    "\n",
    "        else:            \n",
    "            attr_vals, index_dict = ut.get_one_hot_encoding(attr_vals)\n",
    "            for inner_col in attr_vals.T:                \n",
    "                X.append(inner_col) \n",
    "\n",
    "\n",
    "    # convert to numpy arrays for easy handline\n",
    "    X = np.array(X, dtype=float).T\n",
    "    y = np.array(y, dtype = float)\n",
    "    for k, v in x_control.items(): x_control[k] = np.array(v, dtype=float)\n",
    "        \n",
    "    # shuffle the data\n",
    "    perm = list(range(0,len(y))) # shuffle the data before creating each fold\n",
    "    shuffle(perm)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    for k in x_control.keys():\n",
    "        x_control[k] = x_control[k][perm]\n",
    "\n",
    "    # see if we need to subsample the data\n",
    "    if load_data_size is not None:\n",
    "        print(\"Loading only %d examples from the data\" % load_data_size)\n",
    "        X = X[:load_data_size]\n",
    "        y = y[:load_data_size]\n",
    "        for k in x_control.keys():\n",
    "            x_control[k] = x_control[k][:load_data_size]\n",
    "\n",
    "    return X, y, x_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_rule(x_control, class_labels, sensitive_attr):\n",
    "\n",
    "    \"\"\" Compute the p-rule based on Doctrine of disparate impact \"\"\"\n",
    "\n",
    "    if sensitive_attr==\"sex\":\n",
    "        non_prot_all = sum(x_control == 1.0) # non-protected group\n",
    "        prot_all = sum(x_control == 0.0) # protected group\n",
    "        non_prot_pos = sum(class_labels[x_control == 1.0] == 1.0) # non_protected in positive class\n",
    "        prot_pos = sum(class_labels[x_control == 0.0] == 1.0) # protected in positive class\n",
    "    elif sensitive_attr==\"race\":\n",
    "        non_prot_all = sum(x_control == 4.0) # non-protected group\n",
    "        prot_all = sum(x_control != 4.0) # protected group\n",
    "        non_prot_pos = sum(class_labels[x_control == 4.0] == 1.0) # non_protected in positive class\n",
    "        prot_pos = sum(class_labels[x_control != 4.0] == 1.0) # protected in positive class\n",
    "    frac_non_prot_pos = float(non_prot_pos) / float(non_prot_all)\n",
    "    frac_prot_pos = float(prot_pos) / float(prot_all)\n",
    "    p_rule = (frac_prot_pos / frac_non_prot_pos) * 100.0\n",
    "    print\n",
    "    print(\"Total data points: %d\" % (len(x_control)))\n",
    "    print(\"# non-protected examples: %d\" % (non_prot_all))\n",
    "    print(\"# protected examples: %d\" % (prot_all))\n",
    "    print(\"Non-protected in positive class: %d (%0.0f%%)\" % (non_prot_pos, non_prot_pos * 100.0 / non_prot_all))\n",
    "    print(\"Protected in positive class: %d (%0.0f%%)\" % (prot_pos, prot_pos * 100.0 / prot_all))\n",
    "    print(\"P-rule is: %0.0f%%\" % ( p_rule ))\n",
    "    return p_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file 'adult.data' in the current directory...\n",
      "File found in current directory..\n",
      "Looking for file 'adult.test' in the current directory...\n",
      "File found in current directory..\n",
      "Loading only 10000 examples from the data\n",
      "\n",
      "\"sex\" sentitive attribute :\n",
      "\n",
      "Total data points: 10000\n",
      "# non-protected examples: 6743\n",
      "# protected examples: 3257\n",
      "Non-protected in positive class: 2077 (31%)\n",
      "Protected in positive class: 353 (11%)\n",
      "P-rule is: 35%\n",
      "\n",
      "\"race\" sentitive attribute :\n",
      "\n",
      "Total data points: 10000\n",
      "# non-protected examples: 8611\n",
      "# protected examples: 1389\n",
      "Non-protected in positive class: 2204 (26%)\n",
      "Protected in positive class: 226 (16%)\n",
      "P-rule is: 64%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.56941172473897"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Load the adult data \"\"\"\n",
    "X, y, x_control = load_adult_data(load_data_size=10000) # set the argument to none, or no arguments if you want to test with the whole data -- we are subsampling for performance speedup\n",
    "print(\"\\n\\\"sex\\\" sentitive attribute :\\n\")\n",
    "compute_p_rule(x_control[\"sex\"], y, \"sex\") # compute the p-rule in the original data for the sensitive attribute sex\n",
    "print(\"\\n\\\"race\\\" sentitive attribute :\\n\")\n",
    "compute_p_rule(x_control[\"race\"], y, \"race\") # compute the p-rule in the original data for the sensitive attribute race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Split the data into train and test \"\"\"\n",
    "X = ut.add_intercept(X) # add intercept to X before applying the linear classifier (so that the boundary hyperplan in defined as theta^T*X=0)\n",
    "train_fold_size = 0.7\n",
    "x_train, y_train, x_control_train, x_test, y_test, x_control_test = ut.split_into_train_test(X, y, x_control, train_fold_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_fairness_constraints = None\n",
    "apply_accuracy_constraint = None\n",
    "sep_constraint = None\n",
    "\n",
    "loss_function = lf._logistic_loss\n",
    "sensitive_attrs = ['sex', 'race']\n",
    "sensitive_attrs_to_cov_thresh = {}\n",
    "gamma = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_classifier():\n",
    "    w = ut.train_model(x_train, y_train, x_control_train, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "    train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "    distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "    all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "    correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "    cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "    p_rule = print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs)\n",
    "    return w, p_rule, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Classify the data while optimizing for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classifier_fairness_stats(acc_arr, correlation_dict_arr, cov_dict_arr, s_attr_name):\n",
    "    \n",
    "    correlation_dict = ut.get_avg_correlation_dict(correlation_dict_arr)\n",
    "    p_rule = []\n",
    "    non_prot_pos = []\n",
    "    prot_pos = []\n",
    "    for k in s_attr_name:\n",
    "        non_prot_pos.append(correlation_dict[k][1][1])\n",
    "        prot_pos.append(correlation_dict[k][0][1])\n",
    "        p_rule.append((prot_pos[-1] / non_prot_pos[-1]) * 100.0)\n",
    "    \n",
    "    print(\"Accuracy: %0.2f\" % (np.mean(acc_arr)))\n",
    "    for i in range(len(s_attr_name)):\n",
    "        print(\"\\n\", s_attr_name[i], \" :\\n\")\n",
    "        print(\"Protected/non-protected in +ve class: %0.0f%% / %0.0f%%\" % (prot_pos[i], non_prot_pos[i]))\n",
    "        print(\"P-rule achieved: %0.0f%%\" % (p_rule[i]))\n",
    "        print(\"Covariance between sensitive feature and decision from distance boundary : %0.3f\" % (np.mean([v[s_attr_name[i]] for v in cov_dict_arr])))\n",
    "    return p_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1 - Unconstrained (original) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "\n",
      " sex  :\n",
      "\n",
      "Protected/non-protected in +ve class: 8% / 26%\n",
      "P-rule achieved: 30%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.422\n",
      "\n",
      " race  :\n",
      "\n",
      "Protected/non-protected in +ve class: 10% / 25%\n",
      "P-rule achieved: 40%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.159\n"
     ]
    }
   ],
   "source": [
    "# all constraint flags are set to 0 since we want to train an unconstrained (original) classifier\n",
    "apply_fairness_constraints = 0\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "w_uncons, p_uncons, acc_uncons = train_test_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2 - Classifier with fairness constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "Accuracy: 0.83\n",
      "\n",
      " sex  :\n",
      "\n",
      "Protected/non-protected in +ve class: 14% / 14%\n",
      "P-rule achieved: 96%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.017\n",
      "\n",
      " race  :\n",
      "\n",
      "Protected/non-protected in +ve class: 10% / 15%\n",
      "P-rule achieved: 65%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.002\n"
     ]
    }
   ],
   "source": [
    "apply_fairness_constraints = 1 # set this flag to one since we want to optimize accuracy subject to fairness constraints\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "sensitive_attrs_to_cov_thresh = {\"sex\":0, \"race\":{0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}\n",
    "w_f_cons, p_f_cons, acc_f_cons  = train_test_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Classify such that we optimize for fairness subject to a certain loss in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1 - Classifier with accuracy constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "\n",
      " sex  :\n",
      "\n",
      "Protected/non-protected in +ve class: 21% / 24%\n",
      "P-rule achieved: 88%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.039\n"
     ]
    }
   ],
   "source": [
    "sensitive_attrs = ['sex']\n",
    "\n",
    "apply_fairness_constraints = 0 # flag for fairness constraint is set back to0 since we want to apply the accuracy constraint now\n",
    "apply_accuracy_constraint = 1 # now, we want to optimize fairness subject to accuracy constraints\n",
    "sep_constraint = 0\n",
    "gamma = 0.5 # gamma controls how much loss in accuracy we are willing to incur to achieve fairness -- increase gamme to allow more loss in accuracy\n",
    "w_a_cons, p_a_cons, acc_a_cons = train_test_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 - Classifier with \"fine-grained\" accuracy constraint (no +ve misclassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "\n",
      " sex  :\n",
      "\n",
      "Protected/non-protected in +ve class: 86% / 85%\n",
      "P-rule achieved: 100%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.062\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Classify such that we optimize for fairness subject to a certain loss in accuracy \n",
    "In addition, make sure that no points classified as positive by the unconstrained (original) classifier are misclassified.\n",
    "\"\"\"\n",
    "apply_fairness_constraints = 0 # flag for fairness constraint is set back to0 since we want to apply the accuracy constraint now\n",
    "apply_accuracy_constraint = 1 # now, we want to optimize accuracy subject to fairness constraints\n",
    "sep_constraint = 1 # set the separate constraint flag to one, since in addition to accuracy constrains, we also want no misclassifications for certain points (details in demo README.md)\n",
    "gamma = 1000.0\n",
    "w_a_cons_fine, p_a_cons_fine, acc_a_cons_fine  = train_test_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problème dans la partie \"Classifier with accuracy constraint\" sur la P-rule de l'attribut race -> on a enlevé race, explioquer pourquoi (le code n'est pas conçu pour plusieurs sensitive attributes)\n",
    "### Vérifier qu'il ne faut pas inverser l'ordre de sex et race à chaque fois (car race vient avant sex dans la liste des attributs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - Comparison of the two approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classifier_fairness_stats(acc_arr, correlation_dict_arr, cov_dict_arr, s_attr_name):\n",
    "    \n",
    "    correlation_dict = ut.get_avg_correlation_dict(correlation_dict_arr)\n",
    "    p_rule = []\n",
    "    non_prot_pos = []\n",
    "    prot_pos = []\n",
    "    covariance = []\n",
    "    for k in s_attr_name:\n",
    "        non_prot_pos.append(correlation_dict[k][1][1])\n",
    "        prot_pos.append(correlation_dict[k][0][1])\n",
    "        p_rule.append((prot_pos[-1] / non_prot_pos[-1]) * 100.0)\n",
    "    \n",
    "    accuracy = np.mean(acc_arr)\n",
    "    \n",
    "    for i in range(len(s_attr_name)):\n",
    "        covariance.append(np.mean([v[s_attr_name[i]] for v in cov_dict_arr]))\n",
    "        \n",
    "    return p_rule, non_prot_pos, prot_pos, accuracy, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_classifier_comp(loss_function, apply_fairness_constraints=0, apply_accuracy_constraint=0, sep_constraint=0, sensitive_attrs=['sex', 'race'], cov_thresh=0, gamma=0):\n",
    "    \n",
    "    if 'race' in sensitive_attrs:\n",
    "        if 'sex' in sensitive_attrs:\n",
    "            sensitive_attrs_to_cov_thresh = {\"sex\":cov_thresh, \"race\":{0: cov_thresh, 1: cov_thresh, 2: cov_thresh, 3: cov_thresh, 4: cov_thresh}}\n",
    "        else:\n",
    "            sensitive_attrs_to_cov_thresh = {\"race\":{0: cov_thresh, 1: cov_thresh, 2: cov_thresh, 3: cov_thresh, 4: cov_thresh}}\n",
    "    elif 'sex' in sensitive_attrs:\n",
    "        sensitive_attrs_to_cov_thresh = {\"sex\":cov_thresh}\n",
    "    else:\n",
    "        sensitive_attrs_to_cov_thresh = {}\n",
    "    \n",
    "    w = ut.train_model(x_train, y_train, x_control_train, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "    train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "    distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "    all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "    correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "    cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "    \n",
    "    p_rule, non_prot_pos, prot_pos, accuracy, covariance = compute_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs)\n",
    "    \n",
    "    return w, p_rule, test_score, accuracy, covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.1 - Computation with fairness constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_FAIR_sex = []\n",
    "LR_FAIR_race = []\n",
    "LR_FAIR_both = [] # both sex and race as sensitive attributes\n",
    "thresh = np.linspace(2,0,20) # covariance threshold (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "Optimization problem did not converge.. Check the solution returned by the optimizer.\n",
      "Returned solution is:\n",
      "     fun: 2698.423329273193\n",
      "     jac: array([-3.96728516e-04,  1.52984619e-01,  1.65249939e+01,  2.45855408e+01,\n",
      "       -1.64018555e+01, -2.88458862e+01,  3.53787231e+00,  4.45983887e-01,\n",
      "        6.84268188e+00,  3.18704224e+00, -1.59811401e+00,  6.46667480e-01,\n",
      "       -3.50668335e+00, -4.14813232e+00,  6.93206787e-01, -6.14187622e+00,\n",
      "        1.76618347e+01,  1.84396362e+00, -8.63836670e+00, -3.02889352e+03,\n",
      "       -9.42270447e+02,  9.73238831e+01, -3.19793701e-01, -8.56321106e+01,\n",
      "       -1.20365295e+01, -1.79833679e+01, -2.00452271e+01, -9.23080444e+00,\n",
      "        5.53203430e+01,  7.93069458e+00,  1.16631165e+01, -1.05902405e+01,\n",
      "        7.26968384e+00,  7.93728638e+00, -3.16073303e+01, -2.02622814e+04,\n",
      "       -3.10170563e+02,  8.71367188e+01,  9.45867920e+00,  3.82428589e+01,\n",
      "        1.06078522e+02,  6.92533569e+01,  8.62668457e+01,  2.32696533e-01,\n",
      "       -2.38636810e+02,  4.57839966e+00,  9.17846985e+01,  1.82524414e+01,\n",
      "        3.75213318e+01, -3.00719864e+05,  7.76129150e+00])\n",
      " message: 'Positive directional derivative for linesearch'\n",
      "    nfev: 6219\n",
      "     nit: 117\n",
      "    njev: 113\n",
      "  status: 8\n",
      " success: False\n",
      "       x: array([-2.63099711e+00, -6.24518826e-01, -7.67179963e-01, -7.47877029e-01,\n",
      "       -6.93104718e-01, -1.47127872e+00, -1.00993789e+00,  5.44288766e+00,\n",
      "        2.05235457e-01,  3.98234347e-01,  1.72716629e-01,  8.04088752e-01,\n",
      "        1.67645220e+00, -7.42133804e-02,  1.14811311e+00,  1.37491359e+00,\n",
      "        2.97274804e-01, -1.26280512e+00, -2.07236607e+00,  1.52248963e-02,\n",
      "        1.92374618e-02,  9.67258226e-01,  7.51679051e-01,  4.43368212e-02,\n",
      "        1.24649824e+00, -2.67437253e+00, -2.40148462e+00, -6.13253566e-02,\n",
      "        5.94579293e-01,  1.41143056e+00,  1.16232901e+00,  1.33587281e-01,\n",
      "        9.54492818e-01,  9.41625832e-01,  2.29775527e-01,  5.27619042e-04,\n",
      "       -5.66011382e-01, -5.56584617e-01, -8.05002190e-01, -5.96971186e-01,\n",
      "        3.02946895e-02,  1.11828287e+00, -5.31732512e-01,  5.83707980e-01,\n",
      "        6.74561260e-01, -2.66177418e-01, -8.69726498e-01, -6.00335686e-01,\n",
      "       -8.15332000e-02,  2.21017476e-04, -1.43187587e-02])\n"
     ]
    }
   ],
   "source": [
    "for c in thresh:\n",
    "    LR_FAIR_sex.append(train_test_classifier_comp(lf._logistic_loss, apply_fairness_constraints=1, sensitive_attrs=['sex'], cov_thresh=c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "Optimization problem did not converge.. Check the solution returned by the optimizer.\n",
      "Returned solution is:\n",
      "     fun: 308434.6102869014\n",
      "     jac: array([5.28299609e+03, 1.38000000e+02, 3.44000000e+02, 4.02099609e+03,\n",
      "       1.15000000e+02, 4.60000000e+02, 2.04000000e+02, 1.00000000e+00,\n",
      "       4.80199609e+03, 1.73000000e+02, 2.46000000e+02, 7.03000000e+02,\n",
      "       1.60000000e+01, 1.94100000e+03, 1.88000000e+02, 2.70000000e+01,\n",
      "       1.15600000e+03, 6.01996094e+02, 2.30996094e+02, 2.08574980e+05,\n",
      "       1.97611988e+05, 7.24996094e+02, 2.00000000e+00, 7.40000000e+02,\n",
      "       4.98000000e+02, 1.90000000e+02, 2.98000000e+02, 4.46000000e+02,\n",
      "       6.99996094e+02, 3.80000000e+01, 4.79000000e+02, 1.19000000e+02,\n",
      "       6.00996094e+02, 1.84000000e+02, 2.63000000e+02, 3.33374000e+05,\n",
      "       1.60600000e+03, 1.68899609e+03, 1.98000000e+02, 9.27996094e+02,\n",
      "       6.96996094e+02, 1.65000000e+02, 8.68000000e+02, 3.00000000e+00,\n",
      "       1.81200000e+03, 7.90000000e+01, 2.09499609e+03, 2.23000000e+02,\n",
      "       2.03000000e+02, 8.09252000e+05, 5.09419961e+04])\n",
      " message: 'Inequality constraints incompatible'\n",
      "    nfev: 298\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 4\n",
      " success: False\n",
      "       x: array([3.48153998e-02, 2.49927483e-01, 5.36979339e-01, 7.05456350e-03,\n",
      "       9.51635317e-01, 8.33970382e-01, 9.90219783e-01, 3.73327450e-01,\n",
      "       2.08780020e-01, 1.66078678e-01, 2.82484653e-01, 1.24365810e-01,\n",
      "       8.87436315e-01, 4.49167696e-01, 1.08474020e-01, 9.50585027e-01,\n",
      "       6.11698079e-01, 1.69455432e-01, 5.85613790e-01, 5.31791102e-02,\n",
      "       2.41560814e-01, 5.28851904e-01, 1.94178109e-01, 9.81509915e-01,\n",
      "       5.78974299e-01, 7.98180934e-01, 8.99273238e-01, 2.18842750e-01,\n",
      "       6.89533513e-01, 3.89298837e-01, 4.62832887e-01, 4.63618483e-01,\n",
      "       9.26757192e-01, 6.56138573e-01, 2.80393520e-01, 5.54473272e-01,\n",
      "       1.03981963e-01, 6.76250589e-01, 9.12496146e-01, 8.02986946e-01,\n",
      "       3.60537574e-01, 4.13995861e-01, 9.98371408e-01, 3.90366859e-01,\n",
      "       7.18211900e-01, 7.15833286e-02, 1.94193645e-01, 3.68330244e-04,\n",
      "       9.66557498e-01, 1.49306522e-02, 7.79555261e-01])\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "for c in thresh:\n",
    "    LR_FAIR_race.append(train_test_classifier_comp(lf._logistic_loss, apply_fairness_constraints=1, sensitive_attrs=['race'], cov_thresh=c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "Optimization problem did not converge.. Check the solution returned by the optimizer.\n",
      "Returned solution is:\n",
      "     fun: 157059.4410807196\n",
      "     jac: array([ 4.92997461e+03,  1.27000000e+02,  3.15998047e+02,  3.78097852e+03,\n",
      "        8.40000000e+01,  4.26998047e+02,  1.95000000e+02,  0.00000000e+00,\n",
      "        4.47797656e+03,  1.61000000e+02,  2.34000000e+02,  6.18000000e+02,\n",
      "        9.00000000e+00,  1.84698633e+03,  1.51000000e+02,  1.40000000e+01,\n",
      "        1.08899414e+03,  5.82994141e+02,  2.24000000e+02,  1.92942557e+05,\n",
      "        1.83163486e+05,  6.92998047e+02,  2.00000000e+00,  7.07998047e+02,\n",
      "        4.36000000e+02,  1.83998047e+02,  2.88000000e+02,  4.19998047e+02,\n",
      "        6.73994141e+02,  3.70000000e+01,  4.12998047e+02,  1.07998047e+02,\n",
      "        5.49990234e+02,  1.72000000e+02,  2.44998047e+02, -3.33594000e+05,\n",
      "        1.42599805e+03,  1.59199023e+03,  1.89998047e+02,  9.01986328e+02,\n",
      "        6.73000000e+02,  1.47000000e+02,  8.22996094e+02,  2.00000000e+00,\n",
      "        1.60899805e+03,  7.60000000e+01,  2.01097852e+03,  2.16000000e+02,\n",
      "        1.93000000e+02,  8.09252000e+05,  4.70757734e+04])\n",
      " message: 'Inequality constraints incompatible'\n",
      "    nfev: 297\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 4\n",
      " success: False\n",
      "       x: array([ 0.17993842,  0.00960346,  0.06019082,  0.66429622,  0.26669346,\n",
      "        0.08518779,  0.06592431,  0.25700046,  0.45396843,  0.2948873 ,\n",
      "        0.13756458,  0.61577053,  0.53921612,  0.04413908,  0.15441192,\n",
      "        0.21990178,  0.81231979,  0.18921466,  0.31930767, -0.11689512,\n",
      "        0.6257802 ,  0.74684033,  0.56795749,  0.70216063,  0.27885789,\n",
      "        0.60511808,  0.99533924,  0.65609188,  0.15561458,  0.21654089,\n",
      "        0.18815432,  0.79294894,  0.20902619,  0.78283563,  0.74158148,\n",
      "       -0.12688692,  0.66452695,  0.52194926,  0.44305852,  0.14708459,\n",
      "        0.69465466,  0.82137679,  0.11213648,  0.07030107,  0.6038754 ,\n",
      "        0.82498739,  0.35978427,  0.87755026,  0.16480966,  0.00895827,\n",
      "        0.02290368])\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n",
      "table :  sex   [1. 0. 1. ... 1. 0. 1.]\n",
      "table :  race   [4. 2. 4. ... 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "for c in thresh:\n",
    "    LR_FAIR_both.append(train_test_classifier_comp(lf._logistic_loss, apply_fairness_constraints=1, sensitive_attrs=['sex', 'race'], cov_thresh=c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_FAIR_sex_P = []\n",
    "LR_FAIR_sex_ACC = []\n",
    "LR_FAIR_sex_COV = []\n",
    "\n",
    "LR_FAIR_race_P = []\n",
    "LR_FAIR_race_ACC = []\n",
    "LR_FAIR_race_COV = []\n",
    "\n",
    "LR_FAIR_both_Psex = [] # p%-rule for the attribute sex, computed with a model trained giving both sensitive arguments\n",
    "LR_FAIR_both_Prace = [] # p%-rule for the attribute race, computed with a model trained giving both sensitive arguments\n",
    "LR_FAIR_both_ACC = []\n",
    "LR_FAIR_both_COVsex = [] # covariance measure for the attribute sex, computed with a model trained giving both sensitive arguments\n",
    "LR_FAIR_both_COVrace = [] # covariance measure for the attribute race, computed with a model trained giving both sensitive arguments\n",
    "\n",
    "for i in range(len(thresh)):\n",
    "    LR_FAIR_sex_P.append(*LR_FAIR_sex[i][1])\n",
    "    LR_FAIR_sex_ACC.append(LR_FAIR_sex[i][3])\n",
    "    LR_FAIR_sex_COV.append(*LR_FAIR_sex[i][4])\n",
    "    \n",
    "    LR_FAIR_race_P.append(*LR_FAIR_race[i][1])\n",
    "    LR_FAIR_race_ACC.append(LR_FAIR_race[i][3])\n",
    "    LR_FAIR_race_COV.append(*LR_FAIR_race[i][4])\n",
    "    \n",
    "    LR_FAIR_both_Psex.append(LR_FAIR_both[i][1][0])\n",
    "    LR_FAIR_both_Prace.append(LR_FAIR_both[i][1][1])\n",
    "    LR_FAIR_both_ACC.append(LR_FAIR_both[i][3])\n",
    "    LR_FAIR_both_COVsex.append(LR_FAIR_both[i][4][0])\n",
    "    LR_FAIR_both_COVrace.append(LR_FAIR_both[i][4][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2 - Computation with accuracy constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_ACCURACY_sex = []\n",
    "LR_FGACCURACY_sex = []\n",
    "gamma = np.linspace(2,0,20) # maximal additional loss (gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gamma:\n",
    "    LR_ACCURACY_sex.append(train_test_classifier_comp(lf._logistic_loss, apply_accuracy_constraint=1, sensitive_attrs=['sex'], gamma=g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization problem did not converge.. Check the solution returned by the optimizer.\n",
      "Returned solution is:\n",
      "     fun: 1459597.912562444\n",
      "     jac: array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.03125000e+00,\n",
      "        7.34375000e-01,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "       -3.12500000e-02,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  8.82812500e+00,\n",
      "        0.00000000e+00, -1.56250000e-02,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00, -1.56250000e-02,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  1.31671875e+02,  1.09375000e-01])\n",
      " message: 'Inequality constraints incompatible'\n",
      "    nfev: 5353\n",
      "     nit: 94\n",
      "    njev: 93\n",
      "  status: 4\n",
      " success: False\n",
      "       x: array([-5.78365874e+08, -5.54112056e+08, -5.54177449e+08, -5.54131035e+08,\n",
      "       -5.54149867e+08, -5.54148297e+08, -5.54182782e+08, -5.54167228e+08,\n",
      "        2.42612379e+04, -3.52801420e+08, -3.52667098e+08, -3.52755318e+08,\n",
      "       -3.52760750e+08, -3.52765973e+08, -3.52775625e+08, -3.52770669e+08,\n",
      "       -3.52739207e+08, -3.52772055e+08, -3.52768364e+08, -3.12467837e+02,\n",
      "       -3.23559251e+02, -2.00889115e+08, -2.04212573e+08, -2.00869795e+08,\n",
      "       -2.00933377e+08, -2.00885957e+08, -2.00895373e+08, -2.00868815e+08,\n",
      "       -2.00906743e+08, -2.00894638e+08, -2.00888211e+08, -2.00892725e+08,\n",
      "       -2.00870322e+08, -2.00852070e+08, -2.00945975e+08, -1.26045025e+01,\n",
      "        4.24412439e+07,  4.24659306e+07,  4.24774488e+07,  4.24428074e+07,\n",
      "        4.24849358e+07,  4.24947669e+07,  1.64371204e+09, -1.29007374e+10,\n",
      "        1.64367136e+09,  1.64368575e+09,  1.64368771e+09,  1.64364741e+09,\n",
      "        1.64366674e+09,  4.68921234e-04,  2.16604531e+03])\n"
     ]
    }
   ],
   "source": [
    "for g in gamma:\n",
    "    LR_FGACCURACY_sex.append(train_test_classifier_comp(lf._logistic_loss, apply_accuracy_constraint=1, sep_constraint=1, sensitive_attrs=['sex'], gamma=g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23115612160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresh, LR_FAIR_sex_P, label='LR_FAIR_sex')\n",
    "plt.plot(thresh, LR_FAIR_race_P, label='LR_FAIR_race')\n",
    "plt.plot(thresh, LR_FAIR_both_Psex, label='LR_FAIR_both_sex')\n",
    "plt.plot(thresh, LR_FAIR_sex_P, label='LR_FAIR_both_race')\n",
    "plt.xlim(np.max(thresh), np.min(thresh))\n",
    "plt.legend()\n",
    "plt.xlabel('covariance threshold (c)')\n",
    "plt.ylabel('p%-rule')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
